{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "EEG.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "OyWWIHOnDIyJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from zipfile import ZipFile\n",
        "import numpy as np\n",
        "import pickle\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DyICX22fDLme",
        "colab_type": "code",
        "outputId": "165e7a93-a895-4641-c3d7-492a0be63a93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "! wget --user rijulganguly --password rZQRfkap http://www.eecs.qmul.ac.uk/mmv/datasets/deap/data/data_preprocessed_python.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-10-20 18:08:06--  http://www.eecs.qmul.ac.uk/mmv/datasets/deap/data/data_preprocessed_python.zip\n",
            "Resolving www.eecs.qmul.ac.uk (www.eecs.qmul.ac.uk)... 138.37.95.147\n",
            "Connecting to www.eecs.qmul.ac.uk (www.eecs.qmul.ac.uk)|138.37.95.147|:80... connected.\n",
            "HTTP request sent, awaiting response... 502 Proxy Error\n",
            "2019-10-20 18:09:51 ERROR 502: Proxy Error.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxv4zESuDIyO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filename = \"data_preprocessed_python.zip\"\n",
        "m = \"data_preprocessed_python/s\"\n",
        "num = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70ObhMU7DIyS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dest_dir = \"/content\"\n",
        "with ZipFile(filename) as zf:\n",
        "    zf.extractall(dest_dir)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BrSFXQhTDIyV",
        "colab_type": "code",
        "outputId": "04977cea-2f58-4dd6-ed99-b723d92ffb89",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 778kB 2.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 348kB 32.8MB/s \n",
            "\u001b[31mERROR: jupyter-console 5.2.0 has requirement prompt-toolkit<2.0.0,>=1.0.0, but you'll have prompt-toolkit 2.0.10 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement ipython~=5.5.0, but you'll have ipython 7.8.0 which is incompatible.\u001b[0m\n",
            "\u001b[K     |████████████████████████████████| 122kB 2.8MB/s \n",
            "\u001b[31mERROR: jupyter-console 5.2.0 has requirement prompt-toolkit<2.0.0,>=1.0.0, but you'll have prompt-toolkit 2.0.10 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement ipykernel~=4.6.0, but you'll have ipykernel 5.1.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement ipython~=5.5.0, but you'll have ipython 7.8.0 which is incompatible.\u001b[0m\n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hhXWyQ6NDIyY",
        "colab_type": "code",
        "outputId": "4aa0717b-54e1-4f98-ff6a-09aca08633ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34msample_data\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6kPpS__6DIyc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idpFfiugDIye",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = pickle.load(open('data_preprocessed_python/s04.dat', 'rb'), encoding='iso-8859-1')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JhZvGrfmDIyg",
        "colab_type": "code",
        "outputId": "c595c58d-e609-4daf-9993-8e4a4781f4fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x['labels'][0][0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6.68"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gX1DcOb6DIyk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "datas = {}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5D_vGeChDIym",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(1,33):\n",
        "    if(i<10):\n",
        "        eID = \"0\" + str(i)\n",
        "    else:\n",
        "        eID = str(i)\n",
        "        \n",
        "    fLoad = 'data_preprocessed_python/s' + eID + '.dat'\n",
        "    dat = pickle.load(open(fLoad, 'rb'), encoding='iso-8859-1')\n",
        "    \n",
        "    datas[i] = dat"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HxIm1pZ7IwCo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from scipy.stats import kurtosis\n",
        "from scipy.stats import skew\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBnhAtF4NxHc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "changed_data = {}\n",
        "m_in = np.zeros((40,40,101))\n",
        "\n",
        "cnt = 0\n",
        "mj = 0\n",
        "for i in range(1,33):\n",
        "    for j in range(40):\n",
        "        \n",
        "        for k in range(40):\n",
        "            mj = 0 \n",
        "            cnt = 0\n",
        "            \n",
        "            for l in range(10):\n",
        "                m_in[j][k][cnt] = np.mean(datas[i]['data'][j][k][mj:mj+807])\n",
        "                m_in[j][k][cnt+1] = np.std(datas[i]['data'][j][k][mj:mj+807])\n",
        "                m_in[j][k][cnt+2] = np.min(datas[i]['data'][j][k][mj:mj+807])\n",
        "                m_in[j][k][cnt+3] = np.max(datas[i]['data'][j][k][mj:mj+807])\n",
        "                m_in[j][k][cnt+4] = np.median(datas[i]['data'][j][k][mj:mj+807])\n",
        "                m_in[j][k][cnt+5] = np.var(datas[i]['data'][j][k][mj:mj+807])\n",
        "                m_in[j][k][cnt+6] = np.ptp(datas[i]['data'][j][k][mj:mj+807])\n",
        "                m_in[j][k][cnt+7] = skew(datas[i]['data'][j][k][mj:mj+807])\n",
        "                m_in[j][k][cnt+8] = kurtosis(datas[i]['data'][j][k][mj:mj+807])\n",
        "                \n",
        "                cnt += 9\n",
        "                mj += 807\n",
        "\n",
        "                if(mj > 8064):\n",
        "                    mj = 8064\n",
        "\n",
        "            m_in[j][k][cnt] = np.mean(datas[i]['data'][j][k][:8064])\n",
        "            m_in[j][k][cnt+1] = np.std(datas[i]['data'][j][k][:8064])\n",
        "            m_in[j][k][cnt+2] = np.min(datas[i]['data'][j][k][:8064])\n",
        "            m_in[j][k][cnt+3] = np.max(datas[i]['data'][j][k][:8064])\n",
        "            m_in[j][k][cnt+4] = np.median(datas[i]['data'][j][k][:8064])\n",
        "            m_in[j][k][cnt+5] = np.var(datas[i]['data'][j][k][:8064])\n",
        "            m_in[j][k][cnt+6] = np.ptp(datas[i]['data'][j][k][:8064])\n",
        "            m_in[j][k][cnt+7] = skew(datas[i]['data'][j][k][:8064])\n",
        "            m_in[j][k][cnt+8] = kurtosis(datas[i]['data'][j][k][:8064])\n",
        "\n",
        "            m_in[j][k][cnt+9] = i\n",
        "\n",
        "            m_in[j][k][cnt+10] = j+1\n",
        "\n",
        "    changed_data[i] = m_in\n",
        "    m_in = np.zeros((40,40,101))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GMzujTtxU3Bb",
        "colab_type": "code",
        "outputId": "85cb7cfb-d8c2-4045-ef3c-86a0a72be0ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        " changed_data[32].transpose().shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(101, 40, 40)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kBr7vrzbIX1n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.functional as F\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E6wHcWQYIcDh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CNetValence(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNetValence, self).__init__()\n",
        "        self.layer1 = nn.Sequential(nn.Conv2d(1,100, kernel_size=(3,3)),\n",
        "                                    nn.Tanh()\n",
        "                                    )\n",
        "        self.layer2 = nn.Sequential(nn.Conv2d(100,100, kernel_size=(3,3)),\n",
        "                                    nn.Tanh(),\n",
        "                                    nn.MaxPool2d(kernel_size=(2,2)),\n",
        "                                    nn.Dropout(0.25))\n",
        "        \n",
        "        self.layer3 = nn.Sequential(nn.Linear(100*18*48, 128),\n",
        "                                    nn.Tanh(),\n",
        "                                    nn.Dropout(0.5))\n",
        "        self.final_layer = nn.Sequential(nn.Linear(128,3),\n",
        "                                         nn.Softplus())\n",
        "        \n",
        "        \n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        out = out.view(40,-1)\n",
        "        out = self.layer3(out)\n",
        "        out = self.final_layer(out)\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UxgYNr6oJ7hz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = CNetValence()\n",
        "t = torch.from_numpy(changed_data[32].reshape((40,1,40,101))).float()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IbimUbYaDIyo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "otpt = model(t)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odznt1u4DIys",
        "colab_type": "code",
        "outputId": "1a850da4-7f49-4df9-c7e1-be688e1d61a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "otpt.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([40, 3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AskVT4uFDIyu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#v,ind = torch.max(otpt,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-wQikr0DIyw",
        "colab_type": "code",
        "outputId": "6aca2142-f211-4845-b2a4-14d49bc3cf44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 689
        }
      },
      "source": [
        "otpt"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.5404, 0.7000, 0.6748],\n",
              "        [0.5468, 0.9656, 0.7143],\n",
              "        [0.7076, 0.8055, 0.5747],\n",
              "        [0.4931, 0.9042, 0.6076],\n",
              "        [0.6904, 1.0092, 0.7034],\n",
              "        [0.4268, 0.6764, 0.5138],\n",
              "        [0.5537, 0.8721, 0.6545],\n",
              "        [0.6370, 0.6938, 0.7884],\n",
              "        [0.6810, 1.1190, 0.7615],\n",
              "        [0.4899, 0.8707, 0.6514],\n",
              "        [0.6138, 0.8304, 0.6692],\n",
              "        [0.7473, 0.7879, 0.7366],\n",
              "        [0.6335, 0.6455, 0.7381],\n",
              "        [0.6162, 0.9297, 0.6868],\n",
              "        [0.4649, 0.8498, 0.6386],\n",
              "        [0.5527, 0.8219, 0.7330],\n",
              "        [0.7362, 0.6538, 0.6068],\n",
              "        [0.5468, 0.9404, 0.6082],\n",
              "        [0.6008, 0.7468, 0.8381],\n",
              "        [0.6858, 0.8552, 0.5984],\n",
              "        [0.6466, 0.9314, 0.6369],\n",
              "        [0.5479, 0.6904, 0.5968],\n",
              "        [0.7546, 0.9109, 0.7021],\n",
              "        [0.5035, 0.9300, 0.5495],\n",
              "        [0.5639, 0.7936, 0.8163],\n",
              "        [0.7024, 0.7934, 0.6789],\n",
              "        [0.6252, 0.7353, 0.7642],\n",
              "        [0.6433, 0.7861, 0.6809],\n",
              "        [0.5669, 0.6564, 0.9103],\n",
              "        [0.6850, 0.7838, 0.6340],\n",
              "        [0.6441, 0.9493, 0.8166],\n",
              "        [0.4553, 0.5575, 0.7039],\n",
              "        [0.6340, 0.8845, 0.5445],\n",
              "        [0.5657, 0.8540, 0.7168],\n",
              "        [0.8254, 0.7550, 0.6208],\n",
              "        [0.5874, 0.8042, 0.7938],\n",
              "        [0.5659, 0.7411, 0.7527],\n",
              "        [0.6473, 0.7404, 0.6264],\n",
              "        [0.5718, 0.8912, 0.7370],\n",
              "        [0.5282, 1.0127, 0.6580]], grad_fn=<SoftplusBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DfJACGw0DIyy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "changed_labels = {}\n",
        "m_lab = np.zeros((40,))\n",
        "\n",
        "for i in range(1,33):\n",
        "    for j in range(40):\n",
        "\n",
        "        k = datas[i]['labels'][j][0]\n",
        "        if(k>6):\n",
        "            m_lab[j] = 2\n",
        "        elif(k>4):\n",
        "            m_lab[j] = 1\n",
        "        else:\n",
        "            m_lab[j] = 0\n",
        "\n",
        "    \n",
        "    changed_labels[i] = m_lab\n",
        "    m_lab = np.zeros((40,))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dGkda2DiAmdE",
        "colab_type": "code",
        "outputId": "c88bb692-dc5c-4048-8ee7-51328f19b042",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "t_lab = torch.from_numpy(changed_labels[32])\n",
        "t_lab.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([40])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqIm0fIWAo_d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "#ind_c = oneHot(ind)\n",
        "#ind_c.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0_A4dHpTzaK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#l = criterion(otpt, t_lab.type(torch.LongTensor))\n",
        "#l"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1kfTYwtT61-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def oneHot(a):\n",
        "    mt = np.zeros((40,3))\n",
        "\n",
        "    for i in range(40):\n",
        "        if(a[i] == 0):\n",
        "            mt[i][0] = 1\n",
        "        elif(a[i] == 1):\n",
        "            mt[i][1] = 1\n",
        "        else:\n",
        "            mt[i][2] = 1\n",
        "\n",
        "    return torch.from_numpy(mt)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SP5vPu1JU5gr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.00001, momentum=0.9)\n",
        "l_arr = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K7mDWx0Kdl-m",
        "colab_type": "code",
        "outputId": "80c1a943-274e-43e8-86e7-fcd7d2a59120",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "for epoch in range(250):\n",
        "    epoch_acc = 0\n",
        "    num_correct = 0\n",
        "    for i in range(1,31):\n",
        "        for j in range(1,31):\n",
        "            if(j==i):\n",
        "                continue\n",
        "\n",
        "            input = torch.from_numpy(changed_data[j].reshape((40,1,40,101))).float()\n",
        "            labels = torch.from_numpy(changed_labels[j])\n",
        "            labels.requires_grad=True\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            output = model(input)\n",
        "            v,ind = torch.max(output,1)\n",
        "            #ind_n = oneHot(ind)\n",
        "            #ind_n.requires_grad=True\n",
        "            \n",
        "            loss = criterion(output, labels.type(torch.LongTensor))\n",
        "            #l_arr.append(loss)\n",
        "            #num_correct += torch.sum(labels.type(torch.LongTensor) == ind)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        input = torch.from_numpy(changed_data[i].reshape((40,1,40,101))).float()\n",
        "        labels = torch.from_numpy(changed_labels[i])\n",
        "        labels.requires_grad=False\n",
        "\n",
        "        output = model(input)\n",
        "        v,ind = torch.max(output,1)\n",
        "\n",
        "        loss = criterion(output, labels.type(torch.LongTensor))\n",
        "\n",
        "        num_correct += torch.sum(labels.type(torch.LongTensor) == ind)\n",
        "        l_arr.append(loss)\n",
        "        #print(\"WORKING\")\n",
        "\n",
        "\n",
        "\n",
        "    epoch_acc = num_correct.float()/(30*40)\n",
        "\n",
        "    if(epoch%10 == 0):\n",
        "        print(\"EPOCH \", epoch)\n",
        "        print(\"ACCURACY \", epoch_acc)\n",
        "        print(\"LOSS\", loss)\n",
        "\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "EPOCH  0\n",
            "ACCURACY  tensor(0.4233)\n",
            "LOSS tensor(1.0798, grad_fn=<NllLossBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sp9xlanxe8gX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#class DNNValence(nn.Module):"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xMxowxLck7vX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline \n",
        "plt.plot(l_arr)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L48IfW7Wm0YJ",
        "colab_type": "code",
        "outputId": "bac51fec-1270-4ee5-b6de-e88a89b8f33c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "EPOCH  1\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}